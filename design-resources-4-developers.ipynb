{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Design Resources for Developers\n",
    "\n",
    "This notebook includes the code used to scrape the resources from a repo forked from __[Brad Traversy](https://twitter.com/traversymedia)__'s curated list, __[design-resources-for-developers](https://github.com/bradtraversy/design-resources-for-developers)__ and is the final project by __[Andrew J Hughes](https://twitter.com/ajhughesdev)__ for __[Code Louisville](https://codelouisville.org)__'s Data Analytics Course 1 Jan 2023 cohort.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity='all'\n",
    "\n",
    "import platform\n",
    "platform.python_version()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape the Resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import scrapy\n",
    "except:\n",
    "    %pip install scrapy\n",
    "    import scrapy\n",
    "from scrapy.crawler import CrawlerProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "class JsonWritePipeline(object):\n",
    "  \n",
    "    def open_spider(self, spider):\n",
    "        self.file = open('resourceresults.jl', 'w')\n",
    "    \n",
    "    def close_spider(self, spider):\n",
    "        self.file.close()\n",
    "    \n",
    "    def process_item(self, item, spider):\n",
    "        line = json.dumps(dict(item)) + \"\\n\"\n",
    "        self.file.write(line)\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "\n",
    "class ResourceSpider(scrapy.Spider):\n",
    "    name = \"resources\"\n",
    "    start_urls = [\n",
    "        'https://github.com/ajhughesdev/design-resources-for-developers',\n",
    "    ]\n",
    "    custom_settings = {\n",
    "        'LOG_LEVEL': logging.WARNING,\n",
    "        'ITEM_PIPELINES': {'__main__.JsonWritePipeline': 1},\n",
    "        'FEEDS': {'resourceresults.jl': {'format': 'jl', 'overwrite': True}},\n",
    "    }\n",
    "  \n",
    "    def parse(self, response):\n",
    "        for category in response.xpath('//h2'):\n",
    "            category_name = category.xpath('string(.)').extract_first().strip()\n",
    "            resources = []\n",
    "            for resource in category.xpath('./following-sibling::table[1]//tr'):\n",
    "                resource_name_elem = resource.xpath('./td[1]/a/text()')\n",
    "                if not resource_name_elem:\n",
    "                    continue\n",
    "                resource_name = resource.xpath('./td[1]/a/text()').extract_first().strip()\n",
    "                resource_link = resource.xpath('./td[1]/a/@href').extract_first().strip()\n",
    "                resource_desc = resource.xpath('./td[2]/text()').extract_first().strip()\n",
    "                resource_category = category_name\n",
    "                resources.append({'name': resource_name, 'link': resource_link, 'desc': resource_desc, 'category': resource_category})\n",
    "                \n",
    "            yield {'category': category_name, 'resources': resources}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process = CrawlerProcess({\n",
    "    'USER_AGENT': 'Mozilla/4.0 (compatible; MSIE 7.0; Windows NT 5.1)'\n",
    "})\n",
    "\n",
    "process.crawl(ResourceSpider)\n",
    "process.start()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll resourceresults.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tail -n 2 resourceresults.jl"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyze and clean the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  import pandas as pd\n",
    "except:\n",
    "  %pip install pandas\n",
    "  import pandas as pd\n",
    "  \n",
    "df = pd.read_json('resourceresults.jl', lines=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with empty resources\n",
    "df = df[df['resources'].map(len) > 0]\n",
    "\n",
    "# Remove category 'Table of Contents'\n",
    "df = df[df['category'] != 'Table of Contents']\n",
    "# Remove anti-vaxxer facists\n",
    "df = df[df['resources'].apply(lambda x: 'GetAvataaars' not in [r['name'] for r in x])]\n",
    "\n",
    "df.to_json('resourceresults.jl', orient='records')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save cleaned data to a db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# connect to postgresql database\n",
    "conn = psycopg2.connect(database=\"resourcesdb\", user=os.environ.get('PGUSERNAME'), password=os.environ.get('PGPASSWORD'), host=\"localhost\", port=\"5432\")\n",
    "\n",
    "c = conn.cursor()\n",
    "c.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS design_resources_for_devs_resource (\n",
    "        id BIGSERIAL PRIMARY KEY,\n",
    "        name VARCHAR(150) NOT NULL,\n",
    "        \"desc\" TEXT NOT NULL,\n",
    "        link VARCHAR(200) NOT NULL,\n",
    "        category VARCHAR(150) NOT NULL,\n",
    "        CONSTRAINT unique_name_category UNIQUE (name, category)\n",
    "    )''')\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    for resource in row['resources']:\n",
    "        c.execute(\"\"\"\n",
    "            INSERT INTO design_resources_for_devs_resource (id, name, \"desc\", link, category)\n",
    "            VALUES (DEFAULT, %s, %s, %s, %s)\n",
    "            ON CONFLICT ON CONSTRAINT unique_name_category DO NOTHING\n",
    "            \"\"\",\n",
    "            (resource['name'], resource['desc'], resource['link'], row['category']))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9b8a2948497a37195661541516213c57810adce06dd1cc8361d34c745eb5239"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
